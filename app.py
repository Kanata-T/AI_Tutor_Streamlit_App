# app.py
import streamlit as st
import os
from dotenv import load_dotenv
import google.generativeai as genai
import copy # deepcopyã®ãŸã‚

# Deepnoteç’°å¢ƒå¯¾å¿œ
from deepnote_setup import setup_deepnote_environment, load_environment_variables

# coreãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (state_managerã¯ãƒ‡ãƒãƒƒã‚°è¡¨ç¤ºã§ä¸€éƒ¨ä½¿ç”¨)
from core import state_manager

# utilsãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils.config_loader import get_config # get_image_processing_config ã‹ã‚‰æ±ç”¨çš„ãªåå‰ã«å¤‰æ›´ã‚’æƒ³å®š

# uiãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from ui.tutor_mode_ui import render_tutor_mode
from ui.tuning_mode_ui import render_tuning_mode
from ui.display_helpers import display_debug_images_app

# --- åˆæœŸè¨­å®š ---
# Deepnoteç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
setup_deepnote_environment()

load_dotenv()

# Deepnoteç’°å¢ƒã§ã®ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
if not load_environment_variables():
    st.stop()

API_KEY = os.getenv("GEMINI_API_KEY")

if not API_KEY:
    st.error("âš ï¸ Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.error("Deepnoteã® Project Settings > Environment variables ã§ GEMINI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()
try:
    genai.configure(api_key=API_KEY)
    st.success("âœ… Gemini APIæ¥ç¶šæˆåŠŸ")
except Exception as e:
    st.error(f"âŒ Gemini APIã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    st.stop()

# --- Streamlit UIè¨­å®š ---
st.set_page_config(page_title="AIå­¦ç¿’ãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—", layout="wide")

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åŸºæœ¬åˆæœŸåŒ– ---
if "app_mode" not in st.session_state:
    st.session_state.app_mode = "AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼" # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ¼ãƒ‰

if "tutor_initialized" not in st.session_state:
    st.session_state.tutor_initialized = False
if "tuning_initialized" not in st.session_state:
    st.session_state.tuning_initialized = False

# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“ã§å…±é€šã®åˆæœŸåŒ– (åˆå›ã®ã¿å®Ÿè¡Œ) ---
if "common_params_initialized" not in st.session_state:
    app_config = get_config() # config.yaml å…¨ä½“ã‚’ãƒ­ãƒ¼ãƒ‰
    
    # ç”»åƒå‡¦ç†é–¢é€£ã®è¨­å®šã‚’ãƒ­ãƒ¼ãƒ‰
    img_proc_config = app_config.get("image_processing", {})
    cv_trim_config = img_proc_config.get("opencv_trimming", {})
    
    # --- ã“ã“ã§ app_config ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ ---
    st.session_state.app_config = app_config
    
    # AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ãƒ¢ãƒ¼ãƒ‰ãŠã‚ˆã³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã®ã€Œå›ºå®š/ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’configã‹ã‚‰ãƒ­ãƒ¼ãƒ‰
    # OpenCVãƒˆãƒªãƒŸãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    st.session_state.tuning_fixed_cv_params = {
        "apply": cv_trim_config.get("apply", True),
        "padding": cv_trim_config.get("padding", 0),
        "adaptive_thresh_block_size": cv_trim_config.get("adaptive_thresh_block_size", 11),
        "adaptive_thresh_c": cv_trim_config.get("adaptive_thresh_c", 7),
        "min_contour_area_ratio": cv_trim_config.get("min_contour_area_ratio", 0.00005),
        "gaussian_blur_kernel_width": cv_trim_config.get("gaussian_blur_kernel_width", 5),
        "gaussian_blur_kernel_height": cv_trim_config.get("gaussian_blur_kernel_height", 5),
        "morph_open_apply": cv_trim_config.get("morph_open_apply", False),
        "morph_open_kernel_size": cv_trim_config.get("morph_open_kernel_size", 3),
        "morph_open_iterations": cv_trim_config.get("morph_open_iterations", 1),
        "morph_close_apply": cv_trim_config.get("morph_close_apply", False),
        "morph_close_kernel_size": cv_trim_config.get("morph_close_kernel_size", 3),
        "morph_close_iterations": cv_trim_config.get("morph_close_iterations", 1),
        "haar_apply": cv_trim_config.get("haar_apply", False), # config.yaml ã§ True ã«æ›´æ–°æ¨å¥¨
        "haar_rect_h": cv_trim_config.get("haar_rect_h", 22), # config.yaml ã§ 22 ã«æ›´æ–°æ¨å¥¨
        "haar_peak_threshold": cv_trim_config.get("haar_peak_threshold", 7.0), # config.yaml ã§ 7.0 ã«æ›´æ–°æ¨å¥¨
        "h_proj_apply": cv_trim_config.get("h_proj_apply", False), # config.yaml ã§ True ã«æ›´æ–°æ¨å¥¨
        "h_proj_threshold_ratio": cv_trim_config.get("h_proj_threshold_ratio", 0.15), # config.yaml ã§ 0.15 ã«æ›´æ–°æ¨å¥¨
        # --- â–¼ OCRãƒ™ãƒ¼ã‚¹ãƒˆãƒªãƒŸãƒ³ã‚°é–¢é€£ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ config ã‹ã‚‰èª­ã¿è¾¼ã¿ â–¼ ---
        # "ocr_trim_apply_as_fallback": cv_trim_config.get("ocr_trim_apply_as_fallback", True),
        "ocr_trim_padding": cv_trim_config.get("ocr_trim_padding", 0),
        "ocr_trim_lang": cv_trim_config.get("ocr_trim_lang", "eng+jpn"),
        "ocr_trim_min_conf": cv_trim_config.get("ocr_trim_min_conf", 25),
        # --- â–¼ OCRãƒˆãƒªãƒŸãƒ³ã‚°ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ â–¼ ---
        "ocr_trim_min_box_height": cv_trim_config.get("ocr_trim_min_box_height", 5),
        "ocr_trim_max_box_height_ratio": cv_trim_config.get("ocr_trim_max_box_height_ratio", 0.3),
        "ocr_trim_min_box_width": cv_trim_config.get("ocr_trim_min_box_width", 5),
        "ocr_trim_max_box_width_ratio": cv_trim_config.get("ocr_trim_max_box_width_ratio", 0.8),
        "ocr_trim_min_aspect_ratio": cv_trim_config.get("ocr_trim_min_aspect_ratio", 0.05),
        "ocr_trim_max_aspect_ratio": cv_trim_config.get("ocr_trim_max_aspect_ratio", 20.0),
        "ocr_tesseract_config": cv_trim_config.get("ocr_tesseract_config", "--psm 6"),
        # --- â–² ã“ã“ã¾ã§è¿½åŠ  â–² ---
    }
    
    # ãã®ä»–ã®ç”»åƒå‡¦ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    st.session_state.tuning_fixed_other_params = {
        "grayscale": img_proc_config.get("apply_grayscale", True),
        "output_format": img_proc_config.get("default_output_format", "JPEG"),
        "jpeg_quality": img_proc_config.get("default_jpeg_quality", 85),
        "max_pixels": img_proc_config.get("default_max_pixels_for_resizing", 4000000),
    }
    
    st.session_state.common_params_initialized = True
    # ãƒ‡ãƒãƒƒã‚°ç”¨ã«åˆæœŸåŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
    print("[App] Common parameters (including image processing fixed params from config) initialized.")
    print(f"[App] Initial tuning_fixed_cv_params: {st.session_state.tuning_fixed_cv_params}")
    print(f"[App] Initial tuning_fixed_other_params: {st.session_state.tuning_fixed_other_params}")

# --- ãƒ¢ãƒ¼ãƒ‰ã”ã¨ã®åˆæœŸåŒ–ãƒ•ãƒ©ã‚°ç®¡ç† (å„renderé–¢æ•°å†…ã§å®Ÿéš›ã®åˆæœŸåŒ–å‡¦ç†) ---
# ãƒ¢ãƒ¼ãƒ‰ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã€ã¾ãŸã¯åˆã‚ã¦ãã®ãƒ¢ãƒ¼ãƒ‰ãŒé¸æŠã•ã‚ŒãŸå ´åˆã«ã€
# å¯¾å¿œã™ã‚‹renderé–¢æ•°å†…ã§åˆæœŸåŒ–ãŒè¡Œã‚ã‚Œã‚‹ã‚ˆã†ã«ã€ã“ã“ã§ã¯ãƒ•ãƒ©ã‚°ã®ã¿ã‚’ç®¡ç†ã€‚
# å®Ÿéš›ã®åˆæœŸåŒ–å‡¦ç† (ä¾‹: state_manager.initialize_session_state()) ã¯å„renderé–¢æ•°å†’é ­ã§è¡Œã†ã€‚

if st.session_state.app_mode == "AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼" and not st.session_state.tutor_initialized:
    print(f"[App] AI Tutor mode selected. Tutor needs initialization (current flag: {st.session_state.tutor_initialized}).")
    # render_tutor_mode()å†…ã§ st.session_state.tutor_initialized = True ã¨ãªã‚‹

elif st.session_state.app_mode == "ç”»åƒå‡¦ç†ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°" and not st.session_state.tuning_initialized:
    print(f"[App] Image Tuning mode selected. Tuning needs initialization (current flag: {st.session_state.tuning_initialized}).")
    # render_tuning_mode()å†…ã§ st.session_state.tuning_initialized = True ã¨ãªã‚‹

# --- ãƒ¢ãƒ¼ãƒ‰é¸æŠUI (ã‚µã‚¤ãƒ‰ãƒãƒ¼) ---
current_app_mode = st.session_state.app_mode
selected_mode_in_sidebar = st.sidebar.radio(
    "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ:",
    ("AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼", "ç”»åƒå‡¦ç†ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°"),
    key="app_mode_selector_radio", # ã‚·ãƒ³ãƒ—ãƒ«ãªã‚­ãƒ¼ã«å¤‰æ›´
    index=0 if current_app_mode == "AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼" else 1
)

if selected_mode_in_sidebar != current_app_mode:
    st.session_state.app_mode = selected_mode_in_sidebar
    # ãƒ¢ãƒ¼ãƒ‰å¤‰æ›´æ™‚ã«ã€æ–°ã—ã„ãƒ¢ãƒ¼ãƒ‰ã®åˆæœŸåŒ–ãƒ•ãƒ©ã‚°ã‚’Falseã«ãƒªã‚»ãƒƒãƒˆã—ã¦å†åˆæœŸåŒ–ã‚’ä¿ƒã™
    if st.session_state.app_mode == "AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼":
        st.session_state.tutor_initialized = False
        print("[App] Switched to AI Tutor mode. Reset tutor_initialized flag.")
    elif st.session_state.app_mode == "ç”»åƒå‡¦ç†ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°":
        st.session_state.tuning_initialized = False
        print("[App] Switched to Image Tuning mode. Reset tuning_initialized flag.")
    st.rerun() # ãƒ¢ãƒ¼ãƒ‰å¤‰æ›´ã‚’UIã«å³æ™‚åæ˜ ã•ã›ã‚‹

# --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¨ãƒªã‚¢ã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚° ---
if st.session_state.app_mode == "AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼":
    render_tutor_mode()
elif st.session_state.app_mode == "ç”»åƒå‡¦ç†ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°":
    render_tuning_mode()

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ä¸‹éƒ¨ã®å…±é€šãƒ‡ãƒãƒƒã‚°æƒ…å ± ---
with st.sidebar:
    st.markdown("---")
    if st.session_state.app_mode == "AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼":
        st.header("ãƒ‡ãƒãƒƒã‚°æƒ…å ± (AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼)")
        st.write(f"ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—: `{state_manager.get_current_step()}`") # state_manager ã¯ tutor_mode_ui ã§ä¸»ã«ç®¡ç†
        st.write(f"å‡¦ç†ä¸­: `{st.session_state.get('processing', False)}`")
        st.write(f"æ›–æ˜§ãƒ•ãƒ©ã‚°: `{st.session_state.get('is_request_ambiguous', False)}`")
        st.write(f"æ˜ç¢ºåŒ–è©¦è¡Œ: `{st.session_state.get('clarification_attempts', 0)}`")
        
        # AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ãƒ¢ãƒ¼ãƒ‰ã§ã®ç”»åƒå‡¦ç†ãƒ‡ãƒãƒƒã‚°è¡¨ç¤ºãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹
        show_debug_tutor = st.checkbox(
            "ç”»åƒå‡¦ç†ãƒ‡ãƒãƒƒã‚°è¡¨ç¤º (AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼å®Ÿè¡Œæ™‚)", 
            value=st.session_state.get("show_img_debug_in_tutor_mode", False), # ã‚­ãƒ¼åã‚’çŸ­ç¸®ãƒ»çµ±ä¸€
            key="show_img_debug_tutor_cb"
        )
        st.session_state.show_img_debug_in_tutor_mode = show_debug_tutor
        
        # OCRçµæœãƒ‡ãƒãƒƒã‚°è¡¨ç¤ºãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹
        show_ocr_debug = st.checkbox(
            "OCRçµæœè©³ç´°è¡¨ç¤º (æ–‡å­—èµ·ã“ã—çµæœ)", 
            value=st.session_state.get("show_ocr_debug_in_tutor_mode", False),
            key="show_ocr_debug_tutor_cb"
        )
        st.session_state.show_ocr_debug_in_tutor_mode = show_ocr_debug

        if st.session_state.show_img_debug_in_tutor_mode and \
           st.session_state.get("last_debug_images_tutor_run_final_v3"): # ã“ã®ã‚­ãƒ¼åã¯ tutor_mode_ui.py ã§è¨­å®šã•ã‚Œã‚‹ã‚‚ã®
            with st.expander("å‰å›ã®ç”»åƒå‡¦ç†è©³ç´° (AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼)", expanded=False):
                display_debug_images_app(
                    st.session_state.last_debug_images_tutor_run_final_v3, 
                    title_prefix="å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®"
                )
        
        # OCRçµæœè©³ç´°è¡¨ç¤º
        if st.session_state.show_ocr_debug_in_tutor_mode:
            with st.expander("OCRçµæœè©³ç´° (æ–‡å­—èµ·ã“ã—)", expanded=False):
                # æœ€æ–°ã®OCRçµæœã‚’è¡¨ç¤º
                if st.session_state.get("processed_image_details_list"):
                    st.subheader("ğŸ” æœ€æ–°ã®OCRå‡¦ç†çµæœ")
                    for idx, img_info in enumerate(st.session_state.processed_image_details_list):
                        filename = img_info.get("original_filename", f"ç”»åƒ_{idx+1}")
                        img_type = img_info.get("image_type", "ä¸æ˜")
                        ocr_text = img_info.get("ocr_text", "")
                        
                        st.write(f"**ğŸ“„ {filename}** (ç¨®åˆ¥: {img_type})")
                        
                        # OCRçµæœã®è©³ç´°æƒ…å ±
                        if ocr_text:
                            # æ–‡å­—æ•°ã¨è¡Œæ•°ã®çµ±è¨ˆ
                            char_count = len(ocr_text)
                            line_count = len(ocr_text.split('\n'))
                            word_count = len(ocr_text.split())
                            
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("æ–‡å­—æ•°", char_count)
                            with col2:
                                st.metric("è¡Œæ•°", line_count)
                            with col3:
                                st.metric("å˜èªæ•°", word_count)
                            
                            # OCRãƒ†ã‚­ã‚¹ãƒˆã®è¡¨ç¤º
                            st.text_area(
                                f"æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ ({filename})",
                                value=ocr_text,
                                height=200,
                                disabled=True,
                                key=f"ocr_debug_text_{idx}"
                            )
                            
                            # ãƒ†ã‚­ã‚¹ãƒˆã®å“è³ªè©•ä¾¡
                            if char_count > 0:
                                # æ—¥æœ¬èªæ–‡å­—ã®å‰²åˆ
                                japanese_chars = sum(1 for c in ocr_text if '\u3040' <= c <= '\u309F' or '\u30A0' <= c <= '\u30FF' or '\u4E00' <= c <= '\u9FAF')
                                japanese_ratio = japanese_chars / char_count * 100
                                
                                # è‹±æ•°å­—ã®å‰²åˆ
                                ascii_chars = sum(1 for c in ocr_text if c.isascii() and c.isalnum())
                                ascii_ratio = ascii_chars / char_count * 100
                                
                                st.write("**ğŸ“Š ãƒ†ã‚­ã‚¹ãƒˆå“è³ªåˆ†æ:**")
                                quality_col1, quality_col2 = st.columns(2)
                                with quality_col1:
                                    st.write(f"æ—¥æœ¬èªæ–‡å­—: {japanese_ratio:.1f}%")
                                with quality_col2:
                                    st.write(f"è‹±æ•°å­—: {ascii_ratio:.1f}%")
                        else:
                            st.warning("OCRãƒ†ã‚­ã‚¹ãƒˆãŒæŠ½å‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                        
                        st.markdown("---")
                else:
                    st.info("OCRå‡¦ç†çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦å‡¦ç†ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        
        with st.expander("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆæŠœç²‹ (AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼)", expanded=False):
            # è¡¨ç¤ºã™ã‚‹ã‚­ãƒ¼ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° (ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é–¢é€£ã¨å·¨å¤§ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–)
            tutor_ss_display = {
                k: v for k, v in st.session_state.items() 
                if not k.startswith("tuning_") and \
                   not k.startswith("editable_") and \
                   k not in ["common_params_initialized", "app_mode_selector_radio", 
                              "show_img_debug_tutor_cb", "show_ocr_debug_tutor_cb", 
                              "show_ocr_debug_tuning_cb", "last_debug_images_tutor_run_final_v3",
                              "tuning_fixed_cv_params", "tuning_fixed_other_params",
                              "processed_image_details_list", "tuning_last_ocr_results"] # ã“ã‚Œã‚‰ã¯åˆ¥ã§è¡¨ç¤º/ç®¡ç†
            }
            if "uploaded_file_data" in tutor_ss_display and tutor_ss_display["uploaded_file_data"] is not None:
                if isinstance(tutor_ss_display["uploaded_file_data"], dict):
                     tutor_ss_display["uploaded_file_data"] = {
                        k_i: (f"<bytes {len(v_i)}>" if k_i == "data" and isinstance(v_i, bytes) else v_i)
                        for k_i, v_i in tutor_ss_display["uploaded_file_data"].items()
                    }
                else:
                    tutor_ss_display["uploaded_file_data"] = "<Invalid format>"

            if "messages" in tutor_ss_display and isinstance(tutor_ss_display["messages"], list):
                tutor_ss_display["messages"] = f"<List of {len(tutor_ss_display['messages'])} messages>"
            
            # current_explanation ã¨ initial_analysis_result ã‚‚å·¨å¤§ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§è¦ç´„
            if "current_explanation" in tutor_ss_display and isinstance(tutor_ss_display["current_explanation"], str):
                tutor_ss_display["current_explanation"] = tutor_ss_display["current_explanation"][:200] + "..." if len(tutor_ss_display["current_explanation"]) > 200 else tutor_ss_display["current_explanation"]
            if "initial_analysis_result" in tutor_ss_display and isinstance(tutor_ss_display["initial_analysis_result"], dict):
                 tutor_ss_display["initial_analysis_result"] = f"<Dict with keys: {list(tutor_ss_display['initial_analysis_result'].keys())}>"


            st.json(tutor_ss_display, expanded=False)

    elif st.session_state.app_mode == "ç”»åƒå‡¦ç†ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°":
        st.header("ãƒ‡ãƒãƒƒã‚°æƒ…å ± (ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°)")
        
        # ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã§ã®OCRçµæœãƒ‡ãƒãƒƒã‚°è¡¨ç¤ºãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹
        show_ocr_debug_tuning = st.checkbox(
            "OCRçµæœè©³ç´°è¡¨ç¤º (ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰)", 
            value=st.session_state.get("show_ocr_debug_in_tuning_mode", False),
            key="show_ocr_debug_tuning_cb"
        )
        st.session_state.show_ocr_debug_in_tuning_mode = show_ocr_debug_tuning
        
        # OCRçµæœè©³ç´°è¡¨ç¤ºï¼ˆãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ï¼‰
        if st.session_state.show_ocr_debug_in_tuning_mode:
            with st.expander("OCRçµæœè©³ç´° (ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰)", expanded=False):
                # ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã§ã®æœ€æ–°ã®OCRçµæœã‚’è¡¨ç¤º
                if st.session_state.get("tuning_last_ocr_results"):
                    st.subheader("ğŸ” æœ€æ–°ã®OCRå‡¦ç†çµæœ (ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°)")
                    ocr_results = st.session_state.tuning_last_ocr_results
                    
                    if isinstance(ocr_results, list):
                        for idx, img_info in enumerate(ocr_results):
                            filename = img_info.get("original_filename", f"ç”»åƒ_{idx+1}")
                            img_type = img_info.get("image_type", "ä¸æ˜")
                            ocr_text = img_info.get("ocr_text", "")
                            
                            st.write(f"**ğŸ“„ {filename}** (ç¨®åˆ¥: {img_type})")
                            
                            if ocr_text:
                                # æ–‡å­—æ•°ã¨è¡Œæ•°ã®çµ±è¨ˆ
                                char_count = len(ocr_text)
                                line_count = len(ocr_text.split('\n'))
                                word_count = len(ocr_text.split())
                                
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("æ–‡å­—æ•°", char_count)
                                with col2:
                                    st.metric("è¡Œæ•°", line_count)
                                with col3:
                                    st.metric("å˜èªæ•°", word_count)
                                
                                # OCRãƒ†ã‚­ã‚¹ãƒˆã®è¡¨ç¤º
                                st.text_area(
                                    f"æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ ({filename})",
                                    value=ocr_text,
                                    height=150,
                                    disabled=True,
                                    key=f"ocr_debug_tuning_text_{idx}"
                                )
                            else:
                                st.warning("OCRãƒ†ã‚­ã‚¹ãƒˆãŒæŠ½å‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                            
                            st.markdown("---")
                    else:
                        st.write("OCRçµæœã®å½¢å¼ãŒäºˆæœŸã—ãªã„ã‚‚ã®ã§ã™")
                        st.json(ocr_results)
                else:
                    st.info("OCRå‡¦ç†çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦å‡¦ç†ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        
        with st.expander("ç·¨é›†ä¸­ã®CVãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°)", expanded=False):
            st.json(st.session_state.get("tuning_editable_cv_params", {}))
        with st.expander("ç·¨é›†ä¸­ã®ãã®ä»–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°)", expanded=False):
            st.json(st.session_state.get("tuning_editable_other_params", {}))
        with st.expander("å›ºå®šCVãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (Configç”±æ¥)", expanded=False):
            st.json(st.session_state.get("tuning_fixed_cv_params", {}))
        with st.expander("å›ºå®šãã®ä»–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (Configç”±æ¥)", expanded=False):
            st.json(st.session_state.get("tuning_fixed_other_params", {}))