# app.py
import streamlit as st
import os
from dotenv import load_dotenv
import google.generativeai as genai
from typing import Optional, Dict, Any, List
import copy

# coreãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from core import state_manager, tutor_logic

# utilsãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils.image_processor import preprocess_uploaded_image # ã“ã‚Œã¯æœ€æ–°ç‰ˆã‚’ä½¿ã†æƒ³å®š
from utils.config_loader import get_image_processing_config

# --- åˆæœŸè¨­å®š ---
load_dotenv()
API_KEY = os.getenv("GEMINI_API_KEY")

if not API_KEY:
    st.error("Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()
try:
    genai.configure(api_key=API_KEY)
except Exception as e:
    st.error(f"Gemini APIã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    st.stop()

# --- Streamlit UIè¨­å®š ---
st.set_page_config(page_title="AIå­¦ç¿’ãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—", layout="wide")

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– ---
if "app_mode" not in st.session_state:
    st.session_state.app_mode = "AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼"

# ãƒ¢ãƒ¼ãƒ‰ã”ã¨ã®åˆæœŸåŒ–ãƒ•ãƒ©ã‚° (ã“ã‚Œã¯æ®‹ã—ã¦ã‚‚è‰¯ã„ãŒã€ä¸»è¦ãªåˆæœŸåŒ–ã¯ãƒ¢ãƒ¼ãƒ‰åˆ†å²ã®å¤–ã§è¡Œã†)
if "tutor_initialized" not in st.session_state: st.session_state.tutor_initialized = False
if "tuning_initialized" not in st.session_state: st.session_state.tuning_initialized = False

# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“ã§å…±é€šã®åˆæœŸåŒ– (åˆå›ã®ã¿) ---
if "common_params_initialized" not in st.session_state:
    config_img_proc_common = get_image_processing_config()
    config_cv_trim_defaults_common = config_img_proc_common.get("opencv_trimming", {})
    
    # AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ãƒ¢ãƒ¼ãƒ‰ã§ã‚‚ä½¿ç”¨ã™ã‚‹ã€Œå›ºå®šã•ã‚ŒãŸã€æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    st.session_state.tuning_fixed_cv_params = { # ã‚­ãƒ¼åã¯ tuning_ ã§ã™ãŒã€å®Ÿè³ªã€Œå›ºå®šå€¤ã€
        "apply": config_cv_trim_defaults_common.get("apply", True), "padding": 0,
        "adaptive_thresh_block_size": 11, "adaptive_thresh_c": 7,
        "min_contour_area_ratio": 0.00005,"gaussian_blur_kernel_width": 5,"gaussian_blur_kernel_height": 5,
        "morph_open_apply": False,
        "morph_open_kernel_size": config_cv_trim_defaults_common.get("morph_open_kernel_size", 3),
        "morph_open_iterations": config_cv_trim_defaults_common.get("morph_open_iterations", 1),
        "morph_close_apply": False,
        "morph_close_kernel_size": config_cv_trim_defaults_common.get("morph_close_kernel_size", 3),
        "morph_close_iterations": config_cv_trim_defaults_common.get("morph_close_iterations", 1),
        "haar_apply": config_cv_trim_defaults_common.get("haar_apply", True), "haar_rect_h": 22,
        "haar_peak_threshold": 7.0, "h_proj_apply": config_cv_trim_defaults_common.get("h_proj_apply", True),
        "h_proj_threshold_ratio": 0.15,
    }
    st.session_state.tuning_fixed_other_params = { # ã“ã‚Œã‚‚ã€Œå›ºå®šå€¤ã€
        "grayscale": config_img_proc_common.get("apply_grayscale", True),
        "output_format": config_img_proc_common.get("default_output_format", "JPEG"),
        "jpeg_quality": config_img_proc_common.get("default_jpeg_quality", 85),
        "max_pixels": config_img_proc_common.get("default_max_pixels_for_resizing", 4000000),
    }
    st.session_state.common_params_initialized = True
    print("[App] Common image processing fixed params initialized.")

# AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ãƒ¢ãƒ¼ãƒ‰ç”¨ã®åˆæœŸåŒ–
if st.session_state.app_mode == "AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼" and not st.session_state.tutor_initialized:
    state_manager.initialize_session_state()
    st.session_state.tutor_initialized = True
    st.session_state.tuning_initialized = False
    print("[App] AI Tutor mode specific state initialized.")

# ç”»åƒãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰å°‚ç”¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–
if st.session_state.app_mode == "ç”»åƒå‡¦ç†ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°" and not st.session_state.tuning_initialized:
    st.session_state.tuning_raw_image_data = None
    st.session_state.tuning_raw_image_mime_type = None
    st.session_state.tuning_current_debug_images = []
    st.session_state.tuning_image_key_counter = 0
    st.session_state.tuning_trigger_reprocess = False
    
    # ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°UIç”¨ã®ç·¨é›†å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (å›ºå®šå€¤ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦é–‹å§‹)
    # tuning_fixed_cv_params ã¯æ—¢ã«å…±é€šåˆæœŸåŒ–ã§è¨­å®šã•ã‚Œã¦ã„ã‚‹ã¯ãš
    if "tuning_editable_cv_params" not in st.session_state or not st.session_state.tuning_initialized:
        st.session_state.tuning_editable_cv_params = copy.deepcopy(st.session_state.tuning_fixed_cv_params)
    if "tuning_editable_other_params" not in st.session_state or not st.session_state.tuning_initialized:
        st.session_state.tuning_editable_other_params = copy.deepcopy(st.session_state.tuning_fixed_other_params)
    if "selected_param_set_name_tuning" not in st.session_state or not st.session_state.tuning_initialized:
        st.session_state.selected_param_set_name_tuning = "00: å›ºå®šå€¤ (æ¨å¥¨)"
        
    st.session_state.tuning_initialized = True
    st.session_state.tutor_initialized = False
    print("[App] Image Tuning mode specific state initialized.")


# --- ãƒ¢ãƒ¼ãƒ‰é¸æŠ ---
current_app_mode_for_radio_ui_final_v2 = st.session_state.app_mode
new_app_mode_selected_ui_final_v2 = st.sidebar.radio(
    "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ:", ("AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼", "ç”»åƒå‡¦ç†ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°"),
    key="app_mode_selector_radio_main_v5", # ã‚­ãƒ¼ã®ä¸€æ„æ€§ã‚’ä¿ã¤
    index=0 if current_app_mode_for_radio_ui_final_v2 == "AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼" else 1
)
if new_app_mode_selected_ui_final_v2 != current_app_mode_for_radio_ui_final_v2:
    st.session_state.app_mode = new_app_mode_selected_ui_final_v2
    if new_app_mode_selected_ui_final_v2 == "AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼": st.session_state.tutor_initialized = False # å†åˆæœŸåŒ–ã‚’ä¿ƒã™
    else: st.session_state.tuning_initialized = False # å†åˆæœŸåŒ–ã‚’ä¿ƒã™
    st.rerun()

# ã‚¿ã‚¤ãƒˆãƒ«è¨­å®š (ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦)
if st.session_state.app_mode == "AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼": st.title("AIå­¦ç¿’ãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—")
else: st.title("ğŸ–¼ï¸ OpenCV ç”»åƒãƒˆãƒªãƒŸãƒ³ã‚° ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒŠãƒ¼")


# --- UIãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
def display_analysis_result(analysis_data: Dict[str, Any], title: str = "åˆ†æçµæœ"):
    with st.expander(title, expanded=False):
        if isinstance(analysis_data, dict):
            if "error" in analysis_data: st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {analysis_data['error']}")
            else: st.json(analysis_data)
            if "ocr_text_from_extraction" in analysis_data:
                st.text_area("åˆæœŸåˆ†ææ™‚OCR:", analysis_data.get("ocr_text_from_extraction"), height=100, key=f"exp_ocr_{title.replace(' ','_').lower()}_disp_full")
        else: st.write(analysis_data)

def display_debug_images_app(debug_images_list: List[Dict[str, Any]], title_prefix: str = ""):
    if not debug_images_list:
        if st.session_state.app_mode == "ç”»åƒå‡¦ç†ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°":
             st.info("ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã—ã¦ã€Œé¸æŠã—ãŸè¨­å®šã§å†å‡¦ç†ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã‹ã€æ–°ã—ã„ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return
    st.markdown("---"); st.subheader(f"ğŸ¨ {title_prefix}ç”»åƒå‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—")
    tab_names = [item.get("label", f"S{i+1}") for i, item in enumerate(debug_images_list)]
    tabs = st.tabs(tab_names)
    for i, tab_container in enumerate(tabs):
        with tab_container:
            item = debug_images_list[i]
            img_data = item.get("data")
            if img_data: st.image(img_data, caption=f"M:{item.get('mode','?')},S:{item.get('size','?')}", use_container_width=True)
            else: st.warning("ç”»åƒãƒ‡ãƒ¼ã‚¿ãªã—")

# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æœ¬ä½“ ---
if st.session_state.app_mode == "AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼":
    current_step_tutor_main_final = state_manager.get_current_step()
    message_container_tutor_main = st.container(border=False)
    with message_container_tutor_main:
        if st.session_state.get("messages"):
            for i_tutor_main_msg, msg_tutor_main in enumerate(st.session_state.messages):
                with st.chat_message(msg_tutor_main["role"]):
                    content_tutor_main = msg_tutor_main.get("content")
                    if isinstance(content_tutor_main, dict) and "type" in content_tutor_main:
                        if content_tutor_main["type"] == "analysis_result": display_analysis_result(content_tutor_main["data"], content_tutor_main.get("title", f"åˆ†æçµæœ {i_tutor_main_msg}"))
                    elif isinstance(content_tutor_main, str): st.markdown(content_tutor_main)
                    else: st.write(str(content_tutor_main))
    if not st.session_state.get("messages") and current_step_tutor_main_final == state_manager.STEP_INPUT_SUBMISSION:
        st.info("AIå­¦ç¿’ãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ã¸ã‚ˆã†ã“ãï¼ä¸‹ã®å…¥åŠ›æ¬„ã‹ã‚‰è³ªå•ã‚’ã©ã†ãã€‚")

    # 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å—ä»˜ (AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ãƒ¢ãƒ¼ãƒ‰)
    if current_step_tutor_main_final == state_manager.STEP_INPUT_SUBMISSION or \
       (current_step_tutor_main_final == state_manager.STEP_SESSION_END and st.session_state.get("show_new_question_form", True)):
        if current_step_tutor_main_final == state_manager.STEP_SESSION_END:
            if st.button("æ–°ã—ã„è³ªå•ã®æº–å‚™ã‚’å§‹ã‚ã‚‹", key="reset_main_flow_btn_end_tutor_final_v2"):
                state_manager.reset_for_new_session(); st.rerun()
        with st.form("submission_form_tutor_main_final_v2", clear_on_submit=True):
            st.markdown("#### è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:"); user_query_text_tf_f = st.text_input("è³ªå•ãƒ†ã‚­ã‚¹ãƒˆ", key="main_query_text_tf_f", label_visibility="collapsed")
            uploaded_file_tf_f = st.file_uploader("ç”»åƒ (ä»»æ„)", type=["png","jpg","jpeg","webp","gif","bmp"], key="main_file_uploader_tf_f")
            topic_opts_tf_f = ["", "æ–‡æ³•", "èªå½™", "é•·æ–‡èª­è§£", "è‹±ä½œæ–‡", "ãã®ä»–"]; selected_topic_tf_f = st.selectbox("ãƒˆãƒ”ãƒƒã‚¯ (ä»»æ„)", topic_opts_tf_f, key="main_topic_select_tf_f")
            submit_btn_tf_f = st.form_submit_button("ã“ã®å†…å®¹ã§è³ªå•ã™ã‚‹")
            if submit_btn_tf_f:
                if not user_query_text_tf_f and not uploaded_file_tf_f: st.warning("ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã¾ãŸã¯ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ã€‚")
                else:
                    if current_step_tutor_main_final == state_manager.STEP_SESSION_END: state_manager.reset_for_new_session()
                    ocr_input_image_for_llm = None # â˜… OCR/LLMã«æ¸¡ã™ç”»åƒãƒ‡ãƒ¼ã‚¿ â˜…
                    debug_imgs_for_llm_run_final = []

                    if uploaded_file_tf_f:
                        print(f"[AppTutor] Preprocessing image for LLM: {uploaded_file_tf_f.name}")
                        fixed_cv = st.session_state.tuning_fixed_cv_params
                        fixed_other = st.session_state.tuning_fixed_other_params
                        
                        preprocessing_res_llm_final = preprocess_uploaded_image(
                            uploaded_file_data=uploaded_file_tf_f.getvalue(), mime_type=uploaded_file_tf_f.type,
                            max_pixels=fixed_other["max_pixels"],
                            output_format=fixed_other["output_format"],
                            jpeg_quality=fixed_other["jpeg_quality"],
                            grayscale=fixed_other["grayscale"],
                            apply_trimming_opencv_override=fixed_cv.get("apply"),
                            trim_params_override=fixed_cv
                        )
                        if preprocessing_res_llm_final and "error" not in preprocessing_res_llm_final:
                            # â˜… LLM (OCR) ã«ã¯ "ocr_input_image" ã‚’ä½¿ã† â˜…
                            ocr_input_image_for_llm = preprocessing_res_llm_final.get("ocr_input_image")
                            debug_imgs_for_llm_run_final = preprocessing_res_llm_final.get("debug_images", [])
                            if ocr_input_image_for_llm:
                                state_manager.add_message("system", f"ç”»åƒå‡¦ç†å®Œäº† (OCRå…¥åŠ›å½¢å¼: {ocr_input_image_for_llm['mime_type']})")
                            else:
                                st.warning("OCRå…¥åŠ›ç”¨ç”»åƒã®ç”Ÿæˆã«å•é¡ŒãŒã‚ã‚Šã¾ã—ãŸãŒã€å‡¦ç†ã‚’ç¶™ç¶šã—ã¾ã™ã€‚")
                                ocr_input_image_for_llm = preprocessing_res_llm_final.get("processed_image")
                                if ocr_input_image_for_llm:
                                    state_manager.add_message("system", f"ç”»åƒå‡¦ç†å®Œäº† (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å½¢å¼: {ocr_input_image_for_llm['mime_type']})")
                        elif preprocessing_res_llm_final: st.error(f"ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {preprocessing_res_llm_final['error']}")
                        else: st.error("ç”»åƒå‡¦ç†ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ã€‚")
                    st.session_state.last_debug_images_tutor_run_final_v3 = debug_imgs_for_llm_run_final # ãƒ‡ãƒãƒƒã‚°ç”¨
                    # â˜… state_manager ã«ã¯ ocr_input_image_for_llm ã‚’æ¸¡ã™ â˜…
                    state_manager.store_user_input(user_query_text_tf_f, ocr_input_image_for_llm, selected_topic_tf_f)
                    user_msg_content_final = f"è³ªå•: {user_query_text_tf_f}" + (" (ç”»åƒã‚ã‚Š)" if ocr_input_image_for_llm else "")
                    state_manager.add_message("user", user_msg_content_final)
                    state_manager.set_current_step(state_manager.STEP_INITIAL_ANALYSIS); st.rerun()

    elif current_step_tutor_main_final == state_manager.STEP_INITIAL_ANALYSIS:
        if st.session_state.initial_analysis_result is None and not st.session_state.get("processing"): # processingãƒã‚§ãƒƒã‚¯
            state_manager.set_processing_status(True)
            with st.spinner("AIãŒã‚ãªãŸã®è³ªå•ã‚’åˆ†æä¸­ã§ã™..."): analysis_result_ia_f = tutor_logic.perform_initial_analysis_logic()
            state_manager.set_processing_status(False)
            if analysis_result_ia_f:
                if "error" in analysis_result_ia_f:
                    st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {analysis_result_ia_f.get('error')}"); state_manager.add_message("system", f"ã‚¨ãƒ©ãƒ¼(åˆæœŸåˆ†æ): {analysis_result_ia_f.get('error')}")
                    state_manager.set_current_step(state_manager.STEP_INPUT_SUBMISSION); st.session_state.show_new_question_form = True # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ å†è¡¨ç¤º
                else:
                    state_manager.store_initial_analysis_result(analysis_result_ia_f); state_manager.add_message("system", {"type": "analysis_result", "data": dict(analysis_result_ia_f), "title": "AIã«ã‚ˆã‚‹åˆæœŸåˆ†æ"})
                    if st.session_state.is_request_ambiguous: state_manager.set_current_step(state_manager.STEP_CLARIFICATION_NEEDED)
                    else: state_manager.add_message("assistant", "ã”è³ªå•å†…å®¹ã‚’ç†è§£ã—ã¾ã—ãŸã€‚ã©ã®ã‚ˆã†ãªã‚¹ã‚¿ã‚¤ãƒ«ã®è§£èª¬ãŒã”å¸Œæœ›ã§ã™ã‹ï¼Ÿ"); state_manager.set_current_step(state_manager.STEP_SELECT_STYLE)
                st.rerun()
            else: st.error("åˆ†æå‡¦ç†ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ã€‚"); state_manager.add_message("system", "ã‚¨ãƒ©ãƒ¼(åˆæœŸåˆ†æ): çµæœãŒNoneã€‚"); state_manager.set_current_step(state_manager.STEP_INPUT_SUBMISSION); st.session_state.show_new_question_form = True; st.rerun()

    elif current_step_tutor_main_final == state_manager.STEP_CLARIFICATION_NEEDED:
        needs_clar_q_f = False
        if not st.session_state.messages or st.session_state.messages[-1]["role"] == "user" or \
           (st.session_state.messages[-1]["role"] == "system" and "analysis_result" in (st.session_state.messages[-1].get("content", {})).get("type","")):
            if st.session_state.get("clarification_attempts", 0) == 0: needs_clar_q_f = True # åˆå›ã®ã¿è‡ªå‹•ç”Ÿæˆ
        if needs_clar_q_f and not st.session_state.get("processing"):
            st.session_state.clarification_attempts = st.session_state.get("clarification_attempts", 0) + 1
            state_manager.set_processing_status(True)
            with st.spinner("AIãŒç¢ºèªã®ãŸã‚ã®è³ªå•ã‚’æº–å‚™ä¸­ã§ã™..."): q_ai_f = tutor_logic.generate_clarification_question_logic()
            state_manager.set_processing_status(False)
            if q_ai_f and "ã‚¨ãƒ©ãƒ¼" not in q_ai_f: state_manager.add_message("assistant", q_ai_f); state_manager.add_clarification_history_message("assistant", q_ai_f)
            else:
                err_clar_q_f = q_ai_f or "æ˜ç¢ºåŒ–è³ªå•ç”Ÿæˆã‚¨ãƒ©ãƒ¼ã€‚" ; state_manager.add_message("system", f"ã‚¨ãƒ©ãƒ¼(æ˜ç¢ºåŒ–è³ªå•): {err_clar_q_f}")
                state_manager.add_message("assistant", "ç¢ºèªè³ªå•æº–å‚™ã«å•é¡Œã‚ã‚Šã€‚ç¾åœ¨ã®ç†è§£ã§é€²ã¿ã¾ã™ã€‚ã‚¹ã‚¿ã‚¤ãƒ«é¸æŠã¸ã©ã†ãã€‚")
                st.session_state.is_request_ambiguous = False; state_manager.set_current_step(state_manager.STEP_SELECT_STYLE)
            st.rerun()

    elif current_step_tutor_main_final == state_manager.STEP_SELECT_STYLE:
        st.markdown("---"); st.subheader("è§£èª¬ã‚¹ã‚¿ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
        disp_req_style_sel_f = st.session_state.clarified_request_text or (st.session_state.initial_analysis_result.get("summary") if st.session_state.initial_analysis_result else None) or st.session_state.user_query_text
        if disp_req_style_sel_f: st.info(f"ç¾åœ¨ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: ã€Œ{disp_req_style_sel_f}ã€")
        style_opts_sel_f = {"detailed": "è©³ã—ã(æ¨™æº–)", "hint": "ãƒ’ãƒ³ãƒˆã®ã¿", "socratic": "è³ªå•å½¢å¼ã§"}
        curr_style_sel_f = st.session_state.get("selected_explanation_style", "detailed")
        sel_key_style_f = st.radio("å¸Œæœ›ã‚¹ã‚¿ã‚¤ãƒ«:", list(style_opts_sel_f.keys()), format_func=lambda k_sf: style_opts_sel_f[k_sf], index=list(style_opts_sel_f.keys()).index(curr_style_sel_f) if curr_style_sel_f in style_opts_sel_f else 0, key="style_radio_tutor_final_v2", horizontal=True)
        if st.button("ã“ã®ã‚¹ã‚¿ã‚¤ãƒ«ã§è§£èª¬ç”Ÿæˆ", key="confirm_style_tutor_btn_final_v2", type="primary"):
            state_manager.set_explanation_style(sel_key_style_f); state_manager.add_message("user", f"ï¼ˆã‚¹ã‚¿ã‚¤ãƒ«ã€Œ{style_opts_sel_f[sel_key_style_f]}ã€ã‚’é¸æŠï¼‰")
            state_manager.set_current_step(state_manager.STEP_GENERATE_EXPLANATION); st.rerun()

    elif current_step_tutor_main_final == state_manager.STEP_GENERATE_EXPLANATION:
        if st.session_state.current_explanation is None and not st.session_state.get("processing"):
            state_manager.set_processing_status(True)
            with st.spinner("AIãŒè§£èª¬æº–å‚™ä¸­..."): exp_tutor_f = tutor_logic.generate_explanation_logic()
            state_manager.set_processing_status(False)
            if exp_tutor_f and "ã‚¨ãƒ©ãƒ¼" not in exp_tutor_f: state_manager.store_generated_explanation(exp_tutor_f); state_manager.set_current_step(state_manager.STEP_FOLLOW_UP_LOOP)
            else: err_msg_exp_f2 = exp_tutor_f or "è§£èª¬ç”Ÿæˆã‚¨ãƒ©ãƒ¼ã€‚"; state_manager.add_message("system", f"ã‚¨ãƒ©ãƒ¼(è§£èª¬ç”Ÿæˆ): {err_msg_exp_f2}")
            st.rerun()
            
    elif current_step_tutor_main_final == state_manager.STEP_SUMMARIZE:
        if st.session_state.session_summary is None and st.session_state.student_performance_analysis is None and not st.session_state.get("processing"):
            state_manager.set_processing_status(True); sum_txt_f2, ana_rep_f2 = None, None; comb_parts_f2 = []
            with st.spinner("AIãŒè¦ç´„ã¨å­¦ç¿’åˆ†æã‚’æº–å‚™ä¸­..."):
                sum_txt_f2 = tutor_logic.generate_summary_logic()
                if not sum_txt_f2 or "ã‚¨ãƒ©ãƒ¼" in sum_txt_f2: state_manager.add_message("system", f"ã‚¨ãƒ©ãƒ¼(è¦ç´„): {sum_txt_f2 or 'å¤±æ•—'}")
                else: st.session_state.session_summary = sum_txt_f2; comb_parts_f2.append(f"ã€ä»Šå›ã®ã¾ã¨ã‚ã€‘\n\n{sum_txt_f2}")
                ana_rep_f2 = tutor_logic.analyze_student_performance_logic()
                if not ana_rep_f2 or "ã‚¨ãƒ©ãƒ¼" in ana_rep_f2:
                    state_manager.add_message("system", f"ã‚¨ãƒ©ãƒ¼(åˆ†æ): {ana_rep_f2 or 'å¤±æ•—'}"); st.session_state.student_performance_analysis = "åˆ†æå¤±æ•—ã€‚"
                    comb_parts_f2.append("ã€å­¦ç¿’åˆ†æã€‘\n\nåˆ†æå¤±æ•—ã€‚")
                else: st.session_state.student_performance_analysis = ana_rep_f2; comb_parts_f2.append(f"ã€å­¦ç¿’åˆ†æ (Î²ç‰ˆ)ã€‘\n\n{ana_rep_f2}")
            state_manager.set_processing_status(False)
            if comb_parts_f2: state_manager.add_message("assistant", "\n\n---\n\n".join(comb_parts_f2))
            state_manager.set_current_step(state_manager.STEP_SESSION_END); st.session_state.show_new_question_form = True; st.rerun()

    elif current_step_tutor_main_final == state_manager.STEP_SESSION_END:
        if not st.session_state.get("show_new_question_form"): # æ–°è¦è³ªå•ãƒ•ã‚©ãƒ¼ãƒ ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ãªã„å ´åˆã®ã¿
            if st.button("æ–°ã—ã„è³ªå•ã‚’ã™ã‚‹", key="new_q_from_session_end_final_v2", use_container_width=True):
                state_manager.reset_for_new_session(); st.rerun()

    # AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ãƒ¢ãƒ¼ãƒ‰ã®å…±é€šãƒãƒ£ãƒƒãƒˆå…¥åŠ›
    if current_step_tutor_main_final in [state_manager.STEP_CLARIFICATION_NEEDED, state_manager.STEP_FOLLOW_UP_LOOP]:
        if current_step_tutor_main_final == state_manager.STEP_FOLLOW_UP_LOOP and st.session_state.messages and st.session_state.messages[-1]["role"] == "assistant":
            if st.button("âœ… ç†è§£ã—ã¾ã—ãŸ / è¦ç´„ã¸", key="understood_main_btn_final_v2"):
                state_manager.add_message("user", "ï¼ˆç†è§£ã—ã¾ã—ãŸï¼‰"); state_manager.set_current_step(state_manager.STEP_SUMMARIZE); st.rerun()
        chat_disabled_tf_f = st.session_state.get("processing", False)
        if user_chat_input_tf_f := st.chat_input("AIã¸ã®è¿”ç­”ã‚„è¿½åŠ è³ªå•...", disabled=chat_disabled_tf_f, key="main_tutor_chat_input_area_final_v2"):
            state_manager.add_message("user", user_chat_input_tf_f)
            if current_step_tutor_main_final == state_manager.STEP_CLARIFICATION_NEEDED:
                state_manager.add_clarification_history_message("user", user_chat_input_tf_f)
                state_manager.set_processing_status(True)
                with st.spinner("AIãŒå¿œç­”ã‚’åˆ†æä¸­..."): clar_res_f2 = tutor_logic.analyze_user_clarification_logic(user_chat_input_tf_f)
                state_manager.set_processing_status(False)
                if clar_res_f2:
                    state_manager.add_message("system", {"type": "analysis_result", "data": dict(clar_res_f2), "title": "æ˜ç¢ºåŒ–å¿œç­”ã®åˆ†æçµæœ"})
                    if "error" in clar_res_f2: state_manager.add_message("assistant", f"å¿œç­”åˆ†æã‚¨ãƒ©ãƒ¼ã€‚ç¾åœ¨ã®ç†è§£ã§é€²ã¿ã¾ã™ã€‚"); st.session_state.is_request_ambiguous = False; state_manager.set_current_step(state_manager.STEP_SELECT_STYLE)
                    else:
                        state_manager.store_clarification_analysis(clar_res_f2)
                        if not st.session_state.is_request_ambiguous: state_manager.add_message("assistant", clar_res_f2.get("ai_response_to_user","ç†è§£ã—ã¾ã—ãŸã€‚ã‚¹ã‚¿ã‚¤ãƒ«é¸æŠã¸ã€‚")); state_manager.set_current_step(state_manager.STEP_SELECT_STYLE)
                        else: state_manager.add_message("assistant", f"ã‚‚ã†å°‘ã—ç¢ºèªã•ã›ã¦ãã ã•ã„: {clar_res_f2.get('remaining_issue', 'ä¸æ˜ç‚¹ã‚ã‚Š')}")
                else: state_manager.add_message("system", "ã‚¨ãƒ©ãƒ¼(æ˜ç¢ºåŒ–å¿œç­”åˆ†æ): çµæœNoneã€‚"); state_manager.add_message("assistant", "å¿œç­”åˆ†æã‚¨ãƒ©ãƒ¼ã€‚ã‚¹ã‚¿ã‚¤ãƒ«é¸æŠã¸ã€‚"); st.session_state.is_request_ambiguous = False; state_manager.set_current_step(state_manager.STEP_SELECT_STYLE)
                st.rerun()
            elif current_step_tutor_main_final == state_manager.STEP_FOLLOW_UP_LOOP:
                state_manager.set_processing_status(True)
                with st.spinner("AIãŒå¿œç­”æº–å‚™ä¸­..."): followup_resp_f2 = tutor_logic.generate_followup_response_logic(user_chat_input_tf_f)
                state_manager.set_processing_status(False)
                if followup_resp_f2 and "ã‚¨ãƒ©ãƒ¼" not in followup_resp_f2: state_manager.add_message("assistant", followup_resp_f2)
                else: state_manager.add_message("system", f"ã‚¨ãƒ©ãƒ¼(ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—): {followup_resp_f2 or 'å¤±æ•—'}")
                st.rerun()


elif st.session_state.app_mode == "ç”»åƒå‡¦ç†ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°":
    # --- ç”»åƒå‡¦ç†ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã®UIã¨ãƒ­ã‚¸ãƒƒã‚¯ ---
    with st.sidebar:
        st.header("âš™ï¸ å‡¦ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°)")
        st.markdown("#### 1. ç”»åƒã‚’é¸æŠ")
        uploaded_file_obj_tune_complete_v2 = st.file_uploader(
            "èª¿æ•´å¯¾è±¡ã®ç”»åƒ", type=["png", "jpg", "jpeg", "webp", "gif", "bmp"],
            key=f"tuning_file_uploader_{st.session_state.tuning_image_key_counter}_complete_v2"
        )
        if st.button("ç¾åœ¨ã®ç”»åƒã‚’ã‚¯ãƒªã‚¢", key="clear_image_button_tune_complete_v2"):
            st.session_state.tuning_raw_image_data = None; st.session_state.tuning_raw_image_mime_type = None
            st.session_state.tuning_current_debug_images = []; st.session_state.tuning_image_key_counter += 1
            st.session_state.tuning_editable_cv_params = copy.deepcopy(st.session_state.tuning_fixed_cv_params)
            st.session_state.tuning_editable_other_params = copy.deepcopy(st.session_state.tuning_fixed_other_params)
            st.session_state.tuning_trigger_reprocess = False; st.rerun()

        st.markdown("#### 2. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆææ¡ˆ")
        all_presets_tune_complete_v2 = {
            "ç¾åœ¨ã®ç·¨é›†å€¤": {},
            "00: å›ºå®šå€¤ (æ¨å¥¨)": st.session_state.tuning_fixed_cv_params, # config/å›ºå®šå€¤ã‚’å‚ç…§
            "01: åŸºæœ¬ (ãƒ–ãƒ©ãƒ¼ãªã—)": {"apply":True, "padding":15, "adaptive_thresh_block_size":11, "adaptive_thresh_c":7, "min_contour_area_ratio":0.0005, "gaussian_blur_kernel_width":0, "gaussian_blur_kernel_height":0, "morph_open_apply":False, "morph_close_apply":False, "haar_apply":False, "h_proj_apply":False},
            "02: å°ã•ã„æ–‡å­— (Blockå°,Cèª¿æ•´,Openæœ‰)": {"apply":True, "padding":10, "adaptive_thresh_block_size":7, "adaptive_thresh_c":3, "min_contour_area_ratio":0.0001, "gaussian_blur_kernel_width":0, "gaussian_blur_kernel_height":0, "morph_open_apply":True, "morph_open_kernel_size":2, "morph_open_iterations":1, "morph_close_apply":False, "haar_apply":True, "h_proj_apply":True},
        }
        # ä»–ã®ãƒ—ãƒªã‚»ãƒƒãƒˆã‚‚ã“ã“ã«è¿½åŠ ã§ãã¾ã™

        if "selected_param_set_name_tuning" not in st.session_state: st.session_state.selected_param_set_name_tuning = "00: å›ºå®šå€¤ (æ¨å¥¨)"
        selected_set_name_tune_ui_v2 = st.selectbox("ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:", list(all_presets_tune_complete_v2.keys()), key="param_set_tune_select_complete_v2", index=list(all_presets_tune_complete_v2.keys()).index(st.session_state.selected_param_set_name_tuning))
        if selected_set_name_tune_ui_v2 != st.session_state.selected_param_set_name_tuning:
            st.session_state.selected_param_set_name_tuning = selected_set_name_tune_ui_v2
            if selected_set_name_tune_ui_v2 != "ç¾åœ¨ã®ç·¨é›†å€¤":
                new_editable_params_v2 = st.session_state.tuning_fixed_cv_params.copy() # å›ºå®šå€¤ã‚’ãƒ™ãƒ¼ã‚¹ã«
                new_editable_params_v2.update(all_presets_tune_complete_v2[selected_set_name_tune_ui_v2]) # ãƒ—ãƒªã‚»ãƒƒãƒˆã§ä¸Šæ›¸ã
                st.session_state.tuning_editable_cv_params = new_editable_params_v2
            st.rerun()
        
        st.markdown("#### 3. OpenCV ãƒˆãƒªãƒŸãƒ³ã‚°è©³ç´°è¨­å®š")
        editable_cv_tune_v2 = st.session_state.tuning_editable_cv_params
        editable_cv_tune_v2["apply"] = st.checkbox("OpenCVãƒˆãƒªãƒŸãƒ³ã‚°é©ç”¨", value=editable_cv_tune_v2.get("apply"), key="cv_apply_tune_v2")
        if editable_cv_tune_v2["apply"]:
            editable_cv_tune_v2["padding"] = st.number_input("ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°", 0, 200, editable_cv_tune_v2.get("padding"), 1, key="cv_pad_num_v2")
            bs_val_v2 = st.number_input("é©å¿œé–¾å€¤ãƒ–ãƒ­ãƒƒã‚¯(3ä»¥ä¸Šå¥‡æ•°)", 3, value=editable_cv_tune_v2.get("adaptive_thresh_block_size"), step=2, key="cv_block_num_v2")
            editable_cv_tune_v2["adaptive_thresh_block_size"] = bs_val_v2 if bs_val_v2 % 2 != 0 else bs_val_v2 + 1
            editable_cv_tune_v2["adaptive_thresh_c"] = st.number_input("é©å¿œé–¾å€¤C", value=editable_cv_tune_v2.get("adaptive_thresh_c"), step=1, key="cv_c_num_v2")
            editable_cv_tune_v2["min_contour_area_ratio"] = st.number_input("æœ€å°è¼ªéƒ­é¢ç©æ¯”", 0.0, 0.1, editable_cv_tune_v2.get("min_contour_area_ratio"), 0.00001, "%.5f", key="cv_area_num_v2")
            editable_cv_tune_v2["gaussian_blur_kernel_width"] = st.number_input("ãƒ–ãƒ©ãƒ¼å¹…(0ã§ç„¡åŠ¹,å¥‡æ•°)", 0, value=editable_cv_tune_v2.get("gaussian_blur_kernel_width"), step=1, key="cv_blurw_num_v2")
            editable_cv_tune_v2["gaussian_blur_kernel_height"] = st.number_input("ãƒ–ãƒ©ãƒ¼é«˜ã•(0ã§ç„¡åŠ¹,å¥‡æ•°)", 0, value=editable_cv_tune_v2.get("gaussian_blur_kernel_height"), step=1, key="cv_blurh_num_v2")
            st.markdown("###### ãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼å¤‰æ›")
            editable_cv_tune_v2["morph_open_apply"] = st.checkbox("ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°", value=editable_cv_tune_v2.get("morph_open_apply"), key="cv_mopen_cb_v2")
            if editable_cv_tune_v2.get("morph_open_apply"):
                k_op_v2=st.number_input("Openã‚«ãƒ¼ãƒãƒ«(å¥‡æ•°)",1,value=editable_cv_tune_v2.get("morph_open_kernel_size"),step=2,key="cv_mopenk_num_v2")
                editable_cv_tune_v2["morph_open_kernel_size"]=k_op_v2 if k_op_v2%2!=0 else k_op_v2+1
                editable_cv_tune_v2["morph_open_iterations"]=st.number_input("Openã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³",1,value=editable_cv_tune_v2.get("morph_open_iterations"),step=1,key="cv_mopeni_num_v2")
            editable_cv_tune_v2["morph_close_apply"] = st.checkbox("ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°", value=editable_cv_tune_v2.get("morph_close_apply"), key="cv_mclose_cb_v2")
            if editable_cv_tune_v2.get("morph_close_apply"):
                k_cl_v2=st.number_input("Closeã‚«ãƒ¼ãƒãƒ«(å¥‡æ•°)",1,value=editable_cv_tune_v2.get("morph_close_kernel_size"),step=2,key="cv_mclosek_num_v2")
                editable_cv_tune_v2["morph_close_kernel_size"]=k_cl_v2 if k_cl_v2%2!=0 else k_cl_v2+1
                editable_cv_tune_v2["morph_close_iterations"]=st.number_input("Closeã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³",1,value=editable_cv_tune_v2.get("morph_close_iterations"),step=1,key="cv_mclosei_num_v2")
            with st.expander("è£œåŠ©çš„ãƒˆãƒªãƒŸãƒ³ã‚° (å®Ÿé¨“çš„)", expanded=False):
                editable_cv_tune_v2["haar_apply"]=st.checkbox("Haar-Like",value=editable_cv_tune_v2.get("haar_apply"),key="cv_haar_cb_v2")
                if editable_cv_tune_v2.get("haar_apply"):
                    hrh_v2=st.number_input("Haarãƒã‚¹ã‚¯é«˜(å¶æ•°)",4,100,editable_cv_tune_v2.get("haar_rect_h"),2,key="cv_haarrh_num_v2")
                    editable_cv_tune_v2["haar_rect_h"]=hrh_v2 if hrh_v2%2==0 else hrh_v2+1
                    editable_cv_tune_v2["haar_peak_threshold"]=st.number_input("Haarãƒ”ãƒ¼ã‚¯é–¾å€¤",0.0,100.0,editable_cv_tune_v2.get("haar_peak_threshold"),0.5,"%.1f",key="cv_haarpt_num_v2")
                editable_cv_tune_v2["h_proj_apply"]=st.checkbox("æ°´å¹³å°„å½±",value=editable_cv_tune_v2.get("h_proj_apply"),key="cv_hproj_cb_v2")
                if editable_cv_tune_v2.get("h_proj_apply"):
                    editable_cv_tune_v2["h_proj_threshold_ratio"]=st.number_input("æ°´å¹³å°„å½±é–¾å€¤æ¯”",0.001,0.5,editable_cv_tune_v2.get("h_proj_threshold_ratio"),0.001,"%.3f",key="cv_hprojtr_num_v2")

        st.markdown("#### 4. ãã®ä»–å‡¦ç†è¨­å®š")
        editable_other_tune_v2 = st.session_state.tuning_editable_other_params
        editable_other_tune_v2["grayscale"] = st.checkbox("ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«åŒ–", value=editable_other_tune_v2.get("grayscale"), key="grayscale_tune_complete_v2")
        editable_other_tune_v2["max_pixels"] = st.number_input("ãƒªã‚µã‚¤ã‚ºæœ€å¤§ãƒ”ã‚¯ã‚»ãƒ«(0ã§ç„¡åŠ¹)", 0, value=editable_other_tune_v2.get("max_pixels"), step=100000, key="maxpix_tune_complete_v2")

        if st.button("ã“ã®è¨­å®šã§ç”»åƒã‚’å†å‡¦ç†", key="reprocess_tune_btn_complete_v2", type="primary", use_container_width=True, disabled=(st.session_state.tuning_raw_image_data is None)):
            st.session_state.tuning_trigger_reprocess = True
    
    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢è¡¨ç¤º (ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰)
    if st.session_state.tuning_raw_image_data:
        st.markdown("#### å…ƒç”»åƒ (ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¯¾è±¡):")
        st.image(st.session_state.tuning_raw_image_data, caption=f"å…ƒç”»åƒ ({st.session_state.tuning_raw_image_mime_type})", use_container_width=True)
    display_title_tune_complete_v2 = f"ã€Œ{st.session_state.selected_param_set_name_tuning}ã€è¨­å®šã§ã® " if st.session_state.selected_param_set_name_tuning != "ç¾åœ¨ã®ç·¨é›†å€¤" else "ç¾åœ¨ã®è¨­å®šã§ã® "
    display_debug_images_app(st.session_state.tuning_current_debug_images, title_prefix=display_title_tune_complete_v2)

    # ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã®ãƒ­ã‚¸ãƒƒã‚¯
    should_reprocess_tuning_final_v2 = False
    if uploaded_file_obj_tune_complete_v2 and (st.session_state.tuning_raw_image_data is None or uploaded_file_obj_tune_complete_v2.getvalue() != st.session_state.tuning_raw_image_data):
        st.session_state.tuning_raw_image_data = uploaded_file_obj_tune_complete_v2.getvalue(); st.session_state.tuning_raw_image_mime_type = uploaded_file_obj_tune_complete_v2.type
        st.session_state.tuning_current_debug_images = []; should_reprocess_tuning_final_v2 = True
        st.session_state.selected_param_set_name_tuning = "ç¾åœ¨ã®ç·¨é›†å€¤"
        st.session_state.tuning_editable_cv_params = copy.deepcopy(st.session_state.tuning_fixed_cv_params)
        st.session_state.tuning_editable_other_params = copy.deepcopy(st.session_state.tuning_fixed_other_params)
    if st.session_state.get("tuning_trigger_reprocess"):
        should_reprocess_tuning_final_v2 = True; st.session_state.tuning_trigger_reprocess = False

    if should_reprocess_tuning_final_v2 and st.session_state.tuning_raw_image_data:
        print(f"[AppTune] Reprocessing with: CV={st.session_state.tuning_editable_cv_params}, Other={st.session_state.tuning_editable_other_params}")
        editable_cv_p_final_v2 = st.session_state.tuning_editable_cv_params; editable_o_p_final_v2 = st.session_state.tuning_editable_other_params
        params_to_pass_tune_final = {k:v for k,v in editable_cv_p_final_v2.items() if k != "apply"} # applyã¯åˆ¥å¼•æ•°
        # å¥‡æ•°ä¿è¨¼ãªã©ã¯ preprocess_uploaded_image ã¾ãŸã¯ trim_whitespace_opencv å†…éƒ¨ã§å¯¾å¿œ
        with st.spinner("ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”»åƒå‡¦ç†ä¸­..."):
            res_tune_final_v2 = preprocess_uploaded_image(
                uploaded_file_data=st.session_state.tuning_raw_image_data, mime_type=st.session_state.tuning_raw_image_mime_type,
                max_pixels=editable_o_p_final_v2["max_pixels"], grayscale=editable_o_p_final_v2["grayscale"],
                output_format=editable_o_p_final_v2["output_format"], jpeg_quality=editable_o_p_final_v2["jpeg_quality"],
                apply_trimming_opencv_override=editable_cv_p_final_v2.get("apply"), trim_params_override=params_to_pass_tune_final
            )
        if res_tune_final_v2 and "error" not in res_tune_final_v2: st.session_state.tuning_current_debug_images = res_tune_final_v2.get("debug_images", [])
        elif res_tune_final_v2: st.error(f"ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼(Tune): {res_tune_final_v2['error']}"); st.session_state.tuning_current_debug_images = res_tune_final_v2.get("debug_images",[])
        else: st.error("ç”»åƒå‡¦ç†ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼(Tune)ã€‚"); st.session_state.tuning_current_debug_images = []
        st.rerun()

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ä¸‹éƒ¨ã®å…±é€šãƒ‡ãƒãƒƒã‚°æƒ…å ± ---
with st.sidebar:
    st.markdown("---")
    if st.session_state.app_mode == "AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼":
        st.header("ãƒ‡ãƒãƒƒã‚°æƒ…å ± (AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼)")
        st.write(f"ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—: `{state_manager.get_current_step()}`")
        st.write(f"å‡¦ç†ä¸­: `{st.session_state.get('processing', False)}`")
        st.write(f"æ›–æ˜§ãƒ•ãƒ©ã‚°: `{st.session_state.get('is_request_ambiguous', False)}`")
        st.write(f"æ˜ç¢ºåŒ–è©¦è¡Œ: `{st.session_state.get('clarification_attempts', 0)}`")
        st.session_state.show_img_debug_in_tutor_mode_final = st.checkbox("ç”»åƒå‡¦ç†ãƒ‡ãƒãƒƒã‚°è¡¨ç¤º (AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼å®Ÿè¡Œæ™‚)", value=st.session_state.get("show_img_debug_in_tutor_mode_final", False), key="show_img_debug_tutor_cb_final_v2")
        if st.session_state.show_img_debug_in_tutor_mode_final and st.session_state.get("last_debug_images_tutor_run_final_v3"):
            with st.expander("å‰å›ã®ç”»åƒå‡¦ç†è©³ç´° (AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼)", expanded=False):
                display_debug_images_app(st.session_state.last_debug_images_tutor_run_final_v3, title_prefix="å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®")
        with st.expander("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆå…¨ä½“ (AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼)", expanded=False):
            tutor_ss_disp_f = {k:v for k,v in st.session_state.items() if not k.startswith("tuning_") and not k.startswith("editable_") and not k.startswith("ui_") and k != "all_preset_options" and k != "selected_param_set_name_tuning"}
            if "uploaded_file_data" in tutor_ss_disp_f and tutor_ss_disp_f["uploaded_file_data"] is not None:
                tutor_ss_disp_f["uploaded_file_data"] = {k_i:v_i if k_i!="data" else f"<bytes {len(v_i)}>" for k_i,v_i in tutor_ss_disp_f["uploaded_file_data"].items()}
            if "last_debug_images_tutor_run_final_v3" in tutor_ss_disp_f : tutor_ss_disp_f.pop("last_debug_images_tutor_run_final_v3")
            if "messages" in tutor_ss_disp_f and isinstance(tutor_ss_disp_f["messages"], list): tutor_ss_disp_f["messages"] = f"<List of {len(tutor_ss_disp_f['messages'])} messages>"
            st.json(tutor_ss_disp_f)

    elif st.session_state.app_mode == "ç”»åƒå‡¦ç†ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°":
        st.header("ãƒ‡ãƒãƒƒã‚°æƒ…å ± (ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°)")
        with st.expander("ç·¨é›†ä¸­ã®CVãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿", expanded=False): st.json(st.session_state.get("tuning_editable_cv_params", {}))
        with st.expander("ç·¨é›†ä¸­ã®ãã®ä»–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿", expanded=False): st.json(st.session_state.get("tuning_editable_other_params", {}))
        with st.expander("å›ºå®šCVãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (AIãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ç”¨)", expanded=False): st.json(st.session_state.get("tuning_fixed_cv_params", {}))